{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene matrix recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Preparation\n",
    "This step includes import statements, path settings, and function definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path settings\n",
    "project_dir = os.path.dirname(os.path.abspath('.'))\n",
    "conf_dir = os.path.join(project_dir, 'conf')\n",
    "path_conf_path = os.path.join(conf_dir, 'filepaths.yaml')\n",
    "gene_list_conf_path = os.path.join(conf_dir, 'gene_list_names.yaml')\n",
    "gene_type_conf_path = os.path.join(conf_dir, 'gene_biotype.yaml')\n",
    "\n",
    "with open(path_conf_path) as path_conf_file:\n",
    "    path_dict = yaml.safe_load(path_conf_file)\n",
    "    \n",
    "with open(gene_list_conf_path) as gene_list_conf_file:\n",
    "    gene_list_name_dict = yaml.safe_load(gene_list_conf_file)\n",
    "\n",
    "log_dir = os.path.join(project_dir, path_dict['LOG_DIR'])\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "gencode_path = os.path.join(project_dir, path_dict['GENCODE'])\n",
    "prev_gene_mat_path = os.path.join(project_dir, path_dict['An2018'])\n",
    "hgnc_path = os.path.join(project_dir, path_dict['HGNC'])\n",
    "alt_gene_list_path = os.path.join(project_dir, path_dict['An2018_ALT_GENE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "gencode_df = pd.read_table(gencode_path, compression='gzip', comment='#', names=['seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'])  \n",
    "gencode_gene_df = gencode_df[gencode_df['feature'] == 'gene']  # List up only genes\n",
    "gencode_tx_df = gencode_df[gencode_df['feature'] == 'transcript']  # List up only transcripts\n",
    "hgnc_df = pd.read_table(hgnc_path, usecols=['hgnc_id', 'symbol', 'alias_symbol', 'prev_symbol', 'ensembl_gene_id', 'ucsc_id', 'refseq_accession'])\n",
    "prev_gene_mat_df = pd.read_excel(prev_gene_mat_path, sheet_name='8-1 Genesets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse strings of the 'attribute' field in the GENCODE.\n",
    "def parse_attr_str(attr_str):\n",
    "    attrs = attr_str.split(';')\n",
    "    attr_dict = {}\n",
    "    \n",
    "    for attr in attrs:\n",
    "        key, value = attr.split('=')\n",
    "        attr_dict[key] = value\n",
    "        \n",
    "    return attr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse values of the 'attribute' field in the GENCODE\n",
    "gene_to_attr_dict = {}  # Key: GeneID, Value: A dictionary for the information in the 'attribute' columns\n",
    "gene_name_to_ids = defaultdict(list)  # Key: Gene name, Value: The list of gene IDs\n",
    "hgnc_to_ids = defaultdict(list)  # Key: HGNC ID, Value: The list of gene IDs\n",
    "\n",
    "for attr_str in gencode_gene_df['attribute'].values:\n",
    "    attr_dict = parse_attr_str(attr_str)\n",
    "    \n",
    "    if not attr_dict['ID'].endswith('Y'):  # Ignore pseudoautosome region (PAR_Y)\n",
    "        gene_id = attr_dict['ID'].split('.')[0]\n",
    "        gene_to_attr_dict[gene_id] = attr_dict\n",
    "        gene_name_to_ids[attr_dict['gene_name']].append(gene_id)\n",
    "        hgnc_id = attr_dict.get('hgnc_id')\n",
    "        \n",
    "        if hgnc_id is not None:\n",
    "            hgnc_to_ids[hgnc_id].append(gene_id)\n",
    "\n",
    "tx_to_attr_dict = {}  # Key: GeneID, Value: A dictionary for the information in the 'attribute' columns\n",
    "\n",
    "for attr_str in gencode_tx_df['attribute'].values:\n",
    "    attr_dict = parse_attr_str(attr_str)\n",
    "    \n",
    "    if not attr_dict['ID'].endswith('Y'):  # Ignore pseudoautosome region (PAR_Y)\n",
    "        tx_id = attr_dict['ID'].split('.')[0]\n",
    "        tx_to_attr_dict[tx_id] = attr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HGNC file and make a dictionary which key and value are a gene symbol and its ensembl gene ID, respectively.\n",
    "hgnc_df_col_idx = {column: i for i, column in enumerate(hgnc_df.columns.values)}\n",
    "hgnc_df_val = hgnc_df.values\n",
    "\n",
    "symbol_to_gene_ids = {}\n",
    "alias_to_gene_ids = {}\n",
    "prev_symbol_to_gene_ids = {}\n",
    "\n",
    "for hgnc_entry in hgnc_df_val:\n",
    "    gene_symbol = hgnc_entry[hgnc_df_col_idx['symbol']]\n",
    "    alias_symbol_str = hgnc_entry[hgnc_df_col_idx['alias_symbol']]\n",
    "    prev_symbol_str = hgnc_entry[hgnc_df_col_idx['prev_symbol']]\n",
    "    ensembl_gene_id = hgnc_entry[hgnc_df_col_idx['ensembl_gene_id']]\n",
    "    \n",
    "    if ensembl_gene_id is np.nan or gene_to_attr_dict.get(ensembl_gene_id) is None:\n",
    "        gene_ids = None\n",
    "    else:\n",
    "        gencode_symbol = gene_to_attr_dict[ensembl_gene_id]['gene_name']\n",
    "        gene_ids = gene_name_to_ids.get(gencode_symbol)  # From GENCODE v33\n",
    "    \n",
    "    if gene_ids is not None: \n",
    "        symbol_to_gene_ids[gene_symbol] = gene_ids\n",
    "\n",
    "        if alias_symbol_str is not np.nan:\n",
    "            alias_symbols = alias_symbol_str.split('|')\n",
    "\n",
    "            for alias_symbol in alias_symbols:\n",
    "                alias_to_gene_ids[alias_symbol] = gene_ids\n",
    "\n",
    "        if prev_symbol_str is not np.nan:\n",
    "            prev_symbols = prev_symbol_str.split('|')\n",
    "\n",
    "            for prev_symbol in prev_symbols:\n",
    "                prev_symbol_to_gene_ids[prev_symbol] = gene_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find a gene ID from a gene symbol of the HGNC and the GENCODE v33\n",
    "def find_gene_ids(gene_symbol):\n",
    "    # Priority: \n",
    "    # 1. GENCODE v33\n",
    "    # 2. HGNC: symbol -> alias -> previous symbol\n",
    "    # If the gene IDs cannot be found, return None\n",
    "    \n",
    "    # GENCODE v33\n",
    "    gene_ids = gene_name_to_ids.get(gene_symbol)\n",
    "    \n",
    "    # HGNC\n",
    "    if gene_ids is None:\n",
    "        gene_ids = symbol_to_gene_ids.get(gene_symbol)\n",
    "\n",
    "        if gene_ids is None:\n",
    "            gene_ids = alias_to_gene_ids.get(gene_symbol)\n",
    "\n",
    "            if gene_ids is None:\n",
    "                gene_ids = prev_symbol_to_gene_ids.get(gene_symbol)\n",
    "\n",
    "    return gene_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make a list of alternative gene names and IDs for the deprecated genes of An et al., Science, 2018\n",
    "The purpose of this step is to find genes **deprecated in the GENCODE v33** from the *8-1 Genesets* sheet of the *Supplementary Table S8* in An *et al.*, *Science*, 2018 (This is a **previous gene matrix**) and to find their alternatives.\n",
    "\n",
    "*Note: If you alreday have the {alt_gene_list_path} file, skip this step.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is No. of genes deprecated in the GENCODE v33 \n",
    "gene_id_set = set(gene_to_attr_dict.keys())  # From the GENCODE v33\n",
    "prev_gene_ids = np.vectorize(lambda x: x.split('.')[0])(prev_gene_mat_df['EnsemblGeneId'].values)\n",
    "is_depr_gene = np.vectorize(lambda x: x not in gene_id_set)(prev_gene_ids)\n",
    "print(f'No. deprecated genes: {sum(is_depr_gene)}')\n",
    "depr_gene_mat_df = prev_gene_mat_df[is_depr_gene]\n",
    "depr_gene_mat_df.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of deprecated genes with their alternative names and IDs\n",
    "# The genes was in the gene lists An et al., 2018 except previous GENCODE biotype columns\n",
    "# Columns: gene, gene_id, alt_gene, alt_gene_id\n",
    "# Ref: https://www.genecards.org, http://asia.ensembl.org\n",
    "depr_gene_entries = [\n",
    "    ['AKAP2', 'ENSG00000241978.9', 'PALM2AKAP2', 'ENSG00000157654.19'],\n",
    "    ['BTBD8', 'ENSG00000284413.2', 'BTBD8', 'ENSG00000189195.13'],\n",
    "    ['C2orf48', 'ENSG00000163009.8', 'RRM2', 'ENSG00000171848.15'],\n",
    "    ['C3orf36', 'ENSG00000221972.3', 'SLCO2A1', 'ENSG00000174640.15'],\n",
    "    ['C8orf44', 'ENSG00000213865.7', 'SGK3', 'ENSG00000104205.15'],\n",
    "    ['C9orf47', 'ENSG00000186354.10', 'S1PR3', 'ENSG00000213694.5'],\n",
    "    ['HIST1H3B', 'ENSG00000274267.1', 'H3C2', 'ENSG00000286522.1'],\n",
    "    ['HIST1H3C', 'ENSG00000278272.1', 'H3C3', 'ENSG00000287080.1'],\n",
    "    ['SCO2', 'ENSG00000130489.14', 'SCO2', 'ENSG00000284194.2'],\n",
    "    ['TBCE', 'ENSG00000116957.12', 'TBCE', 'ENSG00000284770.2'],\n",
    "    ['TBCE', 'ENSG00000116957.12', 'TBCE', 'ENSG00000285053.1'],\n",
    "    ['TMEM133', 'ENSG00000170647.3', 'ARHGAP42', 'ENSG00000165895.19'],\n",
    "    ['PAML2', 'ENSG00000243444.7', 'PALM2AKAP2', 'ENSG00000157654.19'], \n",
    "]\n",
    "\n",
    "# Write the entries\n",
    "with open(alt_gene_list_path, 'w') as alt_gene_list_file:\n",
    "    print('gene', 'gene_id', 'alt_gene', 'alt_gene_id', sep='\\t', file=alt_gene_list_file)\n",
    "    \n",
    "    for gene_entry in depr_gene_entries:\n",
    "        print(*gene_entry, sep='\\t', file=alt_gene_list_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Update the previous gene matrix to be compatible with GENCODE v33\n",
    "This step replace the deprecated genes of the previous gene matrix with new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of deprecated genes from the previous gene matrix \n",
    "alt_gene_dict = defaultdict(list)\n",
    "\n",
    "with open(alt_gene_list_path) as alt_gene_list_file:\n",
    "    alt_gene_list_file.readline()  # Read the header\n",
    "    \n",
    "    for line in alt_gene_list_file:\n",
    "        fields = line.strip().split('\\t')\n",
    "        prev_gene_id = fields[1].split('.')[0]\n",
    "        alt_gene_id = fields[3].split('.')[0]\n",
    "        alt_gene_dict[prev_gene_id].append(alt_gene_id)\n",
    "\n",
    "# Remove genes in pseudoautosome regions (PAR_Y)\n",
    "prev_gene_mat_df = prev_gene_mat_df[np.vectorize(lambda x: not x.endswith('_PAR_Y'))(prev_gene_mat_df['EnsemblGeneId'].values)]\n",
    "\n",
    "# Values from the previous gene matrix\n",
    "prev_gene_mat_values = prev_gene_mat_df.values\n",
    "prev_gene_mat_cols = prev_gene_mat_df.columns.values\n",
    "col_idx_dict = {colname: i for i, colname in enumerate(prev_gene_mat_cols)}\n",
    "\n",
    "# Get values from the previous gene matrix and store as dictionary\n",
    "prev_gene_mat_dict = {}  # Key: gene ID, Value: a dictionary (gene list name -> its value (0 or 1))\n",
    "\n",
    "for prev_gene_vals in prev_gene_mat_values:\n",
    "    gene_val_dict = {}\n",
    "    \n",
    "    # Get the values for each gene list column\n",
    "    for colname in prev_gene_mat_cols:\n",
    "        gene_list_name = gene_list_name_dict.get(colname)\n",
    "        \n",
    "        if gene_list_name is not None:  # If None, this column is not for gene lists.\n",
    "            gene_val_dict[gene_list_name] = prev_gene_vals[col_idx_dict[colname]]\n",
    "    \n",
    "    prev_gene_id = prev_gene_vals[col_idx_dict['EnsemblGeneId']].split('.')[0]\n",
    "    alt_gene_ids = alt_gene_dict.get(prev_gene_id, [prev_gene_id])  # Change the gene ID if it was deprecated\n",
    "    \n",
    "    # Make up the dictionary for the gene matrix\n",
    "    for gene_id in alt_gene_ids:\n",
    "        same_gene_dict = prev_gene_mat_dict.get(gene_id)\n",
    "        \n",
    "        # Merge values of duplicated genes using logical OR operation\n",
    "        if same_gene_dict is not None:\n",
    "            for gene_list_name in gene_val_dict:\n",
    "                gene_val_dict[gene_list_name] |= same_gene_dict[gene_list_name]\n",
    "    \n",
    "        prev_gene_mat_dict[gene_id] = dict(gene_val_dict)  # To copy deeply\n",
    "\n",
    "# Make a dictionary for the new gene matrix\n",
    "new_gene_mat_dict = {}\n",
    "\n",
    "for gene_id in gene_to_attr_dict:\n",
    "    gene_val_dict = prev_gene_mat_dict.get(gene_id, dict())\n",
    "    gene_val_dict['gene_id'] = gene_to_attr_dict[gene_id]['ID']\n",
    "    gene_val_dict['gene_name'] = gene_to_attr_dict[gene_id]['gene_name']        \n",
    "    new_gene_mat_dict[gene_id] = gene_val_dict\n",
    "\n",
    "# Make a DataFrame for the new gene matrix\n",
    "gene_mat_df = pd.DataFrame.from_dict(new_gene_mat_dict, orient='index')\n",
    "gene_mat_cols = list(gene_mat_df.columns.values)\n",
    "gene_mat_cols = gene_mat_cols[-2:] + gene_mat_cols[:-2]\n",
    "gene_mat_df = gene_mat_df[gene_mat_cols]\n",
    "gene_mat_df.fillna(0, inplace=True)\n",
    "gene_mat_df = gene_mat_df.astype({gene_list_col: 'int64' for gene_list_col in gene_mat_cols[2:]})\n",
    "gene_mat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add GENCODE biotypes as gene list columns into the gene matrix\n",
    "Following columns will be added in this step.\n",
    "1. Protein_coding\n",
    "2. Long_ncRNA\n",
    "3. Small_ncRNA\n",
    "4. Pseudogene\n",
    "5. IG_TR_Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add GENCODE biotypes\n",
    "with open(gene_type_conf_path) as gene_type_conf_file:\n",
    "    biotype_dict = yaml.safe_load(gene_type_conf_file)\n",
    "\n",
    "for biotype_category in biotype_dict:\n",
    "    biotype_set = set(biotype_dict[biotype_category])\n",
    "    gene_mat_val_dict = {gene_id: 1 if gene_to_attr_dict[gene_id]['gene_type'] in biotype_set else 0 for gene_id in gene_to_attr_dict}\n",
    "    gene_mat_df[biotype_category] = pd.Series(gene_mat_val_dict)\n",
    "    \n",
    "gene_mat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Update new gene lists\n",
    "The purpose of the following steps is to update new datasets to our gene matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 01. 102 ASD genes (Satterstrom et al., Cell, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "asd_gene_list_path = os.path.join(project_dir, path_dict['ASD'])\n",
    "asd_df = pd.read_excel(asd_gene_list_path, sheet_name='102_ASD')\n",
    "asd_df.dropna(inplace=True)\n",
    "\n",
    "# Find the 102 ASD genes from the genes of the gene matrix\n",
    "asd_gene_set = set(asd_df['ensembl_gene_id'].values)\n",
    "is_asd_gene = np.vectorize(lambda gene_id: 1 if gene_id in asd_gene_set else 0)(gene_mat_df.index.values)\n",
    "\n",
    "# Update the gene list to the gene matrix\n",
    "asd_colname = gene_list_name_dict['ASD']\n",
    "gene_mat_df[asd_colname] = is_asd_gene\n",
    "gene_mat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02. 299 DDD genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "ddd_gene_list_path = os.path.join(project_dir, path_dict['DDD'])\n",
    "ddd_df = pd.read_excel(ddd_gene_list_path, sheet_name='kaplanis_samocha_denovoWEST_res')\n",
    "ddd_df = ddd_df[ddd_df['significant'] == True]  # Leave only significant genes\n",
    "ddd_df = ddd_df.astype({'hgnc_id': 'int64'})\n",
    "\n",
    "# FInd the 299 DDD genes from the genes of the gene matrix\n",
    "ddd_hgnc_ids = np.vectorize(lambda x: f'HGNC:{x}')(ddd_df['hgnc_id'].values)\n",
    "ddd_hgnc_id_set = set(ddd_hgnc_ids)\n",
    "gene_id_to_hgnc_id = {gene_id: gene_to_attr_dict[gene_id].get('hgnc_id') for gene_id in gene_to_attr_dict}  \n",
    "is_ddd_gene = np.vectorize(lambda gene_id: 1 if gene_id_to_hgnc_id[gene_id] in ddd_hgnc_id_set else 0)(gene_mat_df.index.values)\n",
    "\n",
    "# Update the gene list to the gene matrix\n",
    "ddd_colname = gene_list_name_dict['DDD']\n",
    "gene_mat_df[ddd_colname] = is_ddd_gene\n",
    "gene_mat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 03. Haploinsufficient genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "gnomad_gene_list_path = os.path.join(project_dir, path_dict['GNOMAD_GENE'])\n",
    "gnomad_gene_df = pd.read_table(gnomad_gene_list_path)\n",
    "\n",
    "# Extract HI genes (HI: Haploinsufficient)\n",
    "is_hi_gene_func = lambda pli: pli is not np.nan and pli >= 0.9\n",
    "is_hi_gene = np.vectorize(is_hi_gene_func)(gnomad_gene_df['pLI'].values)\n",
    "hi_gene_df = gnomad_gene_df[is_hi_gene]  \n",
    "\n",
    "# Dictionaries for pLI scores\n",
    "tx_to_pli = {}\n",
    "symbol_to_pli = {}\n",
    "gene_to_pli = {}\n",
    "\n",
    "# Update the 'tx_to_pli' and the 'symbol_to_pli'\n",
    "hi_txs = hi_gene_df['transcript'].values\n",
    "hi_symbols = hi_gene_df['gene'].values\n",
    "hi_plis = hi_gene_df['pLI'].values\n",
    "\n",
    "for tx_id, symbol, pli_score in zip(hi_txs, hi_symbols, hi_plis):\n",
    "    tx_to_pli[tx_id] = pli_score\n",
    "    prev_symbol_pli = symbol_to_pli.get(symbol)\n",
    "    \n",
    "    # Choose the maximum pLI score for duplicated symbols.\n",
    "    if prev_symbol_pli is None or prev_symbol_pli < pli_score:  \n",
    "        symbol_to_pli[symbol] = pli_score\n",
    "\n",
    "# There are 3 steps to update the 'gene_to_pli'\n",
    "# Step 1: Update the 'gene_to_pli' dictionary by getting gene IDs of the transcript IDs via the GENCODE\n",
    "depr_tx_set = set()\n",
    "hi_tx_list = hi_gene_df['transcript'].values\n",
    "\n",
    "for tx_id in hi_tx_list:\n",
    "    attr_dict = tx_to_attr_dict.get(tx_id)\n",
    "    \n",
    "    if attr_dict is None:\n",
    "        depr_tx_set.add(tx_id)\n",
    "    else:\n",
    "        gene_id = attr_dict['Parent'].split('.')[0]\n",
    "        prev_gene_pli = gene_to_pli.get(gene_id)\n",
    "        pli_score = tx_to_pli[tx_id]\n",
    "        \n",
    "        # Choose the maximum pLI score for duplicated genes.\n",
    "        if prev_gene_pli is None or prev_gene_pli < pli_score:    \n",
    "            gene_to_pli[gene_id] = pli_score\n",
    "\n",
    "# Step 2: Update the 'gene_to_pli' dictionary by getting gene IDs of the deprecated transcript IDs using \n",
    "depr_hi_gene_df = hi_gene_df[np.vectorize(lambda tx_id: tx_id in depr_tx_set)(hi_txs)]\n",
    "depr_gene_symbols = depr_hi_gene_df['gene'].values\n",
    "\n",
    "for depr_gene_symbol in depr_gene_symbols:\n",
    "    gene_ids = find_gene_ids(depr_gene_symbol)\n",
    "    \n",
    "    if gene_ids is None:\n",
    "        print(f'{depr_gene_symbol} cannot be found in both the GENCODE and the HGNC.')\n",
    "        continue\n",
    "    \n",
    "    # Update only if the same gene ID does not exist\n",
    "    for gene_id in gene_ids:\n",
    "        if gene_to_pli.get(gene_id) is None:  \n",
    "            gene_to_pli[gene_id] = symbol_to_pli[depr_gene_symbol]\n",
    "\n",
    "# Update the gene matrix\n",
    "# HC: High-confident\n",
    "is_hi_gene = np.vectorize(lambda gene_id: 0 if gene_to_pli.get(gene_id) is None else 1)(gene_mat_df.index.values)  # pLI score >= 0.9\n",
    "is_hc_hi_gene = np.vectorize(lambda gene_id: 1 if gene_to_pli.get(gene_id) is not None and gene_to_pli.get(gene_id) >= 0.995 else 0)(gene_mat_df.index.values)  # pLI score >= 0.995\n",
    "gene_mat_df[gene_list_name_dict['GNOMAD_PLI90']] = is_hi_gene\n",
    "gene_mat_df[gene_list_name_dict['GNOMAD_PLI995']] = is_hc_hi_gene\n",
    "gene_mat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 04. Co-expression network analysis modules associated with ASD (Parikshak et al., Nature, 2016) \n",
    "- Genome wide transcriptome analysis of 251 post-mortem samples of frontal and temporal cortex and cerebellum from 48 individuals with ASD and 49 control subjects\n",
    "- Identified 6 modules significantly associated with ASD of 24 modules from WGCNA in the cortex analysis\n",
    "- Upregulated: CTX.M9, CTX.M19, CTX.M20\n",
    "- Downregulated: CTX.M4, CTX.M10, CTX.M16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "gene_list_key = 'ASD_WGCNA'\n",
    "mat_col_prefix = gene_list_name_dict[gene_list_key]\n",
    "parik_table_path = os.path.join(project_dir, path_dict[gene_list_key])\n",
    "parik_gene_df = pd.read_excel(parik_table_path, sheet_name='TableS2a', header=1)\n",
    "\n",
    "# Split the genes by their modules\n",
    "groupby_module = parik_gene_df.groupby('WGCNA Module Label')\n",
    "asd_module_nums = [4, 9, 10, 16, 19, 20]  # Modules significantly associated with ASD\n",
    "asd_module_dfs = [groupby_module.get_group(asd_module_num) for asd_module_num in asd_module_nums]\n",
    "\n",
    "# Update the gene matrix\n",
    "gencode_gene_ids = gene_mat_df.index.values\n",
    "gencode_gene_id_set = set(gencode_gene_ids)\n",
    "na_gene_dict = defaultdict(list)\n",
    "\n",
    "for i, asd_module_df in enumerate(asd_module_dfs):\n",
    "    module_num = asd_module_nums[i]\n",
    "    module_name = f'CTX.M{module_num}'\n",
    "    mat_col_name = f\"{mat_col_prefix}_{module_name}\"\n",
    "    mod_gene_cnt = len(asd_module_df.index.values)\n",
    "    \n",
    "    # Make a set of gene IDs in the module\n",
    "    mod_gene_ids = asd_module_df['ENSEMBL ID'].values\n",
    "    mod_gene_id_set = set()\n",
    "    mod_gene_symbols = asd_module_df['HGNC Symbol'].values\n",
    "    na_gene_cnt = 0\n",
    "    \n",
    "    for i in range(mod_gene_cnt):\n",
    "        mod_gene_id = mod_gene_ids[i]\n",
    "        mod_gene_symbol = mod_gene_symbols[i]\n",
    "        \n",
    "        if mod_gene_id in gencode_gene_id_set:\n",
    "            mod_gene_id_set.add(mod_gene_id)\n",
    "        else:  # Replace with alternative gene IDs\n",
    "            if mod_gene_symbol is np.nan:  # New mod_gene ID cannot be found.\n",
    "                na_gene_dict[mat_col_name].append(mod_gene_id)\n",
    "                na_gene_cnt += 1\n",
    "            else:\n",
    "                alt_mod_gene_ids = find_gene_ids(mod_gene_symbol)\n",
    "                \n",
    "                for alt_mod_gene_id in alt_mod_gene_ids:\n",
    "                    mod_gene_id_set.add(alt_mod_gene_id)\n",
    "    \n",
    "    # Update\n",
    "    gene_mat_vals = np.vectorize(lambda gene_id: 1 if gene_id in mod_gene_id_set else 0)(gencode_gene_ids)\n",
    "    gene_mat_df[mat_col_name] = gene_mat_vals\n",
    "    print(f'[{mat_col_name}] No. all genes: {mod_gene_cnt}, No. not available genes: {na_gene_cnt}')\n",
    "\n",
    "# Save the dictionary for not available genes as a log\n",
    "log_path_key = f'{gene_list_key}_LOG'\n",
    "log_path = os.path.join(project_dir, path_dict[log_path_key])\n",
    "\n",
    "with open(log_path, 'w') as logfile:\n",
    "    yaml.dump(dict(na_gene_dict), logfile, default_flow_style=False)\n",
    "\n",
    "gene_mat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 05. Nowakowski et al., Science, 2017\n",
    "- scRNA-seq for primary cortical and medial ganglionic eminence (MGE) in developing human telencephalon\n",
    "- From 48 samples with 5.85 ~ 37 PCW\n",
    "- Unbiased clustering and found marker genes for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "gene_list_key = 'SC_Now2017'\n",
    "now_table_path = os.path.join(project_dir, path_dict[gene_list_key])\n",
    "now_gene_df = pd.read_excel(now_table_path, sheet_name='Table5 - Clustermarkers')\n",
    "\n",
    "# Split the genes by their modules\n",
    "mat_col_prefix = gene_list_name_dict[gene_list_key]\n",
    "groupby_cluster = now_gene_df.groupby('cluster')\n",
    "cluster_names = list(groupby_cluster.groups.keys())\n",
    "gene_cluster_dfs = [groupby_cluster.get_group(cluster_name) for cluster_name in cluster_names]\n",
    "\n",
    "# Update the gene matrix\n",
    "mat_indices = gene_mat_df.index.values\n",
    "mat_index_set = set(mat_indices)\n",
    "na_gene_dict = defaultdict(list)\n",
    "\n",
    "for i, gene_cluster_df in enumerate(gene_cluster_dfs):\n",
    "    cluster_name = cluster_names[i]\n",
    "    mat_col_name = f'{mat_col_prefix}_{cluster_name}'\n",
    "    marker_genes = gene_cluster_df['gene'].values\n",
    "    marker_gene_cnt = len(marker_genes)\n",
    "    \n",
    "    # Make a set of marker gene IDs\n",
    "    marker_gene_id_set = set()\n",
    "    na_gene_cnt = 0\n",
    "    \n",
    "    for marker_gene in marker_genes:\n",
    "        marker_gene_ids = find_gene_ids(marker_gene)\n",
    "        \n",
    "        if marker_gene_ids is None:\n",
    "            na_gene_dict[mat_col_name].append(marker_gene)\n",
    "            na_gene_cnt += 1\n",
    "        else:\n",
    "            for marker_gene_id in marker_gene_ids:\n",
    "                marker_gene_id_set.add(marker_gene_id)\n",
    "    \n",
    "    # Update\n",
    "    gene_mat_vals = np.vectorize(lambda gene_id: 1 if gene_id in marker_gene_id_set else 0)(mat_indices)\n",
    "    gene_mat_df[mat_col_name] = gene_mat_vals \n",
    "    print(f'[{mat_col_name}] No. all genes: {marker_gene_cnt}, No. not available genes: {na_gene_cnt}')\n",
    "\n",
    "# Save the dictionary for not available genes as a log\n",
    "log_path_key = f'{gene_list_key}_LOG'\n",
    "log_path = os.path.join(project_dir, path_dict[log_path_key])\n",
    "\n",
    "with open(log_path, 'w') as logfile:\n",
    "    yaml.dump(dict(na_gene_dict), logfile, default_flow_style=False)\n",
    "\n",
    "gene_mat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 06. Li et al., Science, 2018\n",
    "- Single-cell from 9 de-identified postmortem brains (Table S3)\n",
    "- 5 PCW ~ 20 PCW\n",
    "- Marker genes for each cell type of Pallium, CP, DFC, NCX regions in a human brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "gene_list_key = 'SC_Li2018'\n",
    "li_table_path = os.path.join(project_dir, path_dict[gene_list_key])\n",
    "li_gene_df = pd.read_excel(li_table_path, sheet_name='Table S8', header=3)\n",
    "\n",
    "# Split the dataframe into two DataFrames and concatenate them\n",
    "prenatal_gene_df = li_gene_df[['Gene symbol', 'Cell type', 'Age']].copy()\n",
    "adult_gene_df = li_gene_df[['Gene symbol.1', 'Cell type.1', 'Age.1']].copy()\n",
    "adult_gene_df.rename(columns={colname: colname.split('.')[0] for colname in adult_gene_df.columns.values}, inplace=True)\n",
    "adult_gene_df.dropna(inplace=True)\n",
    "li_gene_df = pd.concat([prenatal_gene_df, adult_gene_df], ignore_index=True)\n",
    "\n",
    "# Split the genes by their cell types\n",
    "mat_col_prefix = gene_list_name_dict[gene_list_key]\n",
    "groupby_cell = li_gene_df.groupby('Cell type')\n",
    "cell_names = list(groupby_cell.groups.keys())\n",
    "cell_gene_dfs = [groupby_cell.get_group(cell_name) for cell_name in cell_names]\n",
    "\n",
    "# Update the gene matrix\n",
    "mat_indices = gene_mat_df.index.values\n",
    "na_gene_dict = defaultdict(list)\n",
    "\n",
    "for i, cell_gene_df in enumerate(cell_gene_dfs):\n",
    "    cell_name = cell_names[i]\n",
    "    mat_col_name = f'{mat_col_prefix}_{cell_name}'\n",
    "    marker_genes = cell_gene_df['Gene symbol'].values\n",
    "    marker_gene_cnt = len(marker_genes)\n",
    "    \n",
    "    # Make a set of marker genes\n",
    "    marker_gene_id_set = set()\n",
    "    na_gene_cnt = 0\n",
    "    \n",
    "    for marker_gene in marker_genes:\n",
    "        marker_gene_ids = find_gene_ids(marker_gene)\n",
    "        \n",
    "        if marker_gene_ids is None:\n",
    "            na_gene_dict[mat_col_name].append(marker_gene)\n",
    "            na_gene_cnt += 1\n",
    "        else:\n",
    "            for marker_gene_id in marker_gene_ids:\n",
    "                marker_gene_id_set.add(marker_gene_id)\n",
    "    \n",
    "    # Update\n",
    "    gene_mat_vals = np.vectorize(lambda gene_id: 1 if gene_id in marker_gene_id_set else 0)(mat_indices)\n",
    "    gene_mat_df[mat_col_name] = gene_mat_vals \n",
    "    print(f'[{mat_col_name}] No. all genes: {marker_gene_cnt}, No. not available genes: {na_gene_cnt}')\n",
    "\n",
    "# Save the dictionary for not available genes as a log\n",
    "log_path_key = f'{gene_list_key}_LOG'\n",
    "log_path = os.path.join(project_dir, path_dict[log_path_key])\n",
    "\n",
    "with open(log_path, 'w') as logfile:\n",
    "    yaml.dump(dict(na_gene_dict), logfile, default_flow_style=False)\n",
    "\n",
    "gene_mat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 07. Velmeshev et al., Science, 2019\n",
    "- Single-nucleus sequencing \n",
    "- 41 post-mortem tissue samples including prefrontal cortex (PFC) and anterior cingulate cortex (ACC) from 16 controls and 15 ASD patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "gene_list_key = 'SN_Vel2019'\n",
    "vel_table_path = os.path.join(project_dir, path_dict[gene_list_key])\n",
    "vel_gene_df = pd.read_excel(vel_table_path, sheet_name='cell type markers')\n",
    "vel_gene_df.head()\n",
    "\n",
    "# Split the genes by their modules\n",
    "mat_col_prefix = gene_list_name_dict[gene_list_key]\n",
    "groupby_cell = vel_gene_df.groupby('Cell type')\n",
    "cell_names = list(groupby_cell.groups.keys())\n",
    "cell_gene_dfs = [groupby_cell.get_group(cell_name) for cell_name in cell_names]\n",
    "\n",
    "# Update the gene matrix\n",
    "mat_indices = gene_mat_df.index.values\n",
    "mat_index_set = set(mat_indices)\n",
    "na_gene_dict = defaultdict(list)\n",
    "\n",
    "for i, cell_gene_df in enumerate(cell_gene_dfs):\n",
    "    cell_name = cell_names[i]\n",
    "    mat_col_name = f'{mat_col_prefix}_{cell_name}'\n",
    "    marker_gene_ids = cell_gene_df['Gene ID'].values\n",
    "    marker_gene_names = cell_gene_df['Gene name'].values\n",
    "    marker_gene_cnt = len(marker_genes)\n",
    "    \n",
    "    # Make a set of marker genes\n",
    "    marker_gene_id_set = set()\n",
    "    na_gene_cnt = 0\n",
    "    \n",
    "    for marker_gene_id, marker_gene_name in zip(marker_gene_ids, marker_gene_names):\n",
    "        if marker_gene_id in mat_index_set:\n",
    "            marker_gene_id_set.add(marker_gene_id)\n",
    "        else:\n",
    "            alt_gene_ids = find_gene_ids(marker_gene_name)\n",
    "            \n",
    "            if alt_gene_ids is None:\n",
    "                na_gene_dict[mat_col_name].append(marker_gene_id)\n",
    "                na_gene_cnt += 1\n",
    "            else:\n",
    "                for alt_gene_id in alt_gene_ids:\n",
    "                    marker_gene_id_set.add(alt_gene_id)\n",
    "                    \n",
    "    gene_mat_vals = np.vectorize(lambda gene_id: 1 if gene_id in marker_gene_id_set else 0)(mat_indices)\n",
    "    gene_mat_df[mat_col_name] = gene_mat_vals            \n",
    "    print(f'[{mat_col_name}] No. all genes: {marker_gene_cnt}, No. not available genes: {na_gene_cnt}')\n",
    "\n",
    "# Save the dictionary for not available genes as a log\n",
    "log_path_key = f'{gene_list_key}_LOG'\n",
    "log_path = os.path.join(project_dir, path_dict[log_path_key])\n",
    "\n",
    "with open(log_path, 'w') as logfile:\n",
    "    yaml.dump(dict(na_gene_dict), logfile, default_flow_style=False)\n",
    "    \n",
    "gene_mat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save the gene matrix as a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your own file path in here\n",
    "my_gene_mat_path = os.path.join(project_dir, 'my_gene_matrix.txt')\n",
    "gene_mat_df.to_csv(my_gene_mat_path, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
